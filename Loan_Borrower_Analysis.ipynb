{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "cell_execution_strategy": "setup",
      "authorship_tag": "ABX9TyOfyuvgRmeFFrk/bX965zvy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/btabi/btabi.com/blob/main/Loan_Borrower_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rzIUmFzX_X-Z"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
        "                             f1_score, roc_auc_score, confusion_matrix,\n",
        "                             classification_report)\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('loan_borowwer_data.csv')\n",
        "print(data.head())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_info = data.info()"
      ],
      "metadata": {
        "id": "jUfoAXetAtq1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data.info())\n",
        "print(data.describe())"
      ],
      "metadata": {
        "id": "EGTHw6j6BUtN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data.isnull().sum())"
      ],
      "metadata": {
        "id": "htNVi2FvCxDJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(x='credit.policy', data=data)\n",
        "plt.title('Distribution of credit.policy')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "OI96nDwQD_M3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.get_dummies(data, columns=['purpose'], drop_first=True)"
      ],
      "metadata": {
        "id": "a_WWzOD7FBfX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data.head())"
      ],
      "metadata": {
        "id": "QQUTJDa8FVkI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Load your data into a DataFrame\n",
        "# Replace 'your_data.csv' with the path to your data file\n",
        "df = pd.read_csv('loan_borowwer_data.csv')\n",
        "\n",
        "# List of important variables\n",
        "important_variables = ['fico', 'log.annual.inc', 'int.rate', 'dti', 'revol.util']\n",
        "\n",
        "# Plot distributions\n",
        "plt.figure(figsize=(15, 10))\n",
        "for i, feature in enumerate(important_variables, 1):\n",
        "    plt.subplot(3, 2, i)\n",
        "    sns.histplot(df[feature], kde=True, color='blue', bins=30)\n",
        "    plt.title(f'Distribution of {feature}')\n",
        "    plt.xlabel(feature)\n",
        "    plt.ylabel('Frequency')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "brYcbSmRPIZm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot distributions by target variable (credit.policy)\n",
        "plt.figure(figsize=(15, 10))\n",
        "for i, feature in enumerate(important_variables, 1):\n",
        "    plt.subplot(3, 2, i)\n",
        "    sns.histplot(df[df['credit.policy'] == 1][feature], kde=True, color='green', label='Repaid', bins=30)\n",
        "    sns.histplot(df[df['credit.policy'] == 0][feature], kde=True, color='red', label='Defaulted', bins=30)\n",
        "    plt.title(f'Distribution of {feature} by Loan Outcome')\n",
        "    plt.xlabel(feature)\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "H2Q9_K-LPZzz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Statistical summary of important variables\n",
        "print(df[important_variables].describe())"
      ],
      "metadata": {
        "id": "9dqTzGFsPkmS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = data.drop('credit.policy', axis=1)\n",
        "y = data['credit.policy']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "logreg = LogisticRegression(max_iter=1000)\n",
        "logreg.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "VALYOFD7FqSH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = logreg.predict(X_test)\n",
        "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
        "print('Precision:', precision_score(y_test, y_pred))\n",
        "print('Recall:', recall_score(y_test, y_pred))\n",
        "print('F1 Score:', f1_score(y_test, y_pred))"
      ],
      "metadata": {
        "id": "MMyUTmCRGO5Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()\n",
        "\n",
        "# Classification Report\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "oJSuxHcnGtx5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('loan_borowwer_data.csv')\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Initialize the scaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit and transform the selected columns\n",
        "scaled_data = scaler.fit_transform(df[['int.rate', 'installment', 'log.annual.inc', 'dti', 'fico', 'days.with.cr.line', 'revol.bal', 'revol.util']])\n",
        "\n",
        "# Convert the scaled data back to a DataFrame\n",
        "scaled_df = pd.DataFrame(scaled_data, columns=['int.rate', 'installment', 'log.annual.inc', 'dti', 'fico', 'days.with.cr.line', 'revol.bal', 'revol.util'], index=df.index)\n",
        "\n",
        "# Assign the scaled data back to the original DataFrame\n",
        "df[['int.rate', 'installment', 'log.annual.inc', 'dti', 'fico', 'days.with.cr.line', 'revol.bal', 'revol.util']] = scaled_df"
      ],
      "metadata": {
        "id": "J-bNiqrnJpYJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# List of numerical features\n",
        "numerical_features = ['int.rate', 'installment', 'log.annual.inc', 'dti', 'fico', 'days.with.cr.line', 'revol.bal', 'revol.util']\n",
        "\n",
        "# Create box plots for each numerical feature\n",
        "plt.figure(figsize=(15, 10))\n",
        "for i, feature in enumerate(numerical_features, 1):\n",
        "    plt.subplot(3, 3, i)\n",
        "    sns.boxplot(y=df[feature])\n",
        "    plt.title(f'Box Plot of {feature}')\n",
        "    plt.ylabel(feature)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pi_H42dROXGg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "\n",
        "# Logistic Regression\n",
        "lr = LogisticRegression()\n",
        "lr.fit(X_train, y_train)\n",
        "y_pred_lr = lr.predict(X_test)\n",
        "\n",
        "# Random Forest\n",
        "rf = RandomForestClassifier()\n",
        "rf.fit(X_train, y_train)\n",
        "y_pred_rf = rf.predict(X_test)\n",
        "\n",
        "# Evaluate models\n",
        "def evaluate_model(y_true, y_pred):\n",
        "    print(f'Accuracy: {accuracy_score(y_true, y_pred)}')\n",
        "    print(f'Precision: {precision_score(y_true, y_pred)}')\n",
        "    print(f'Recall: {recall_score(y_true, y_pred)}')\n",
        "    print(f'F1-Score: {f1_score(y_true, y_pred)}')\n",
        "    print(f'ROC-AUC: {roc_auc_score(y_true, y_pred)}')\n",
        "\n",
        "print(\"Logistic Regression:\")\n",
        "evaluate_model(y_test, y_pred_lr)\n",
        "\n",
        "print(\"Random Forest:\")\n",
        "evaluate_model(y_test, y_pred_rf)"
      ],
      "metadata": {
        "id": "64prOMLhMeVn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Cross-validation for Random Forest\n",
        "cv_scores = cross_val_score(rf, X, y, cv=5, scoring='roc_auc')\n",
        "print(f'Cross-Validation ROC-AUC Scores: {cv_scores}')\n",
        "print(f'Mean ROC-AUC: {cv_scores.mean()}')\n"
      ],
      "metadata": {
        "id": "LU88hx5IM31t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "importances = rf.feature_importances_\n",
        "feature_names = X.columns\n",
        "feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances})\n",
        "print(feature_importance_df.sort_values(by='Importance', ascending=False))"
      ],
      "metadata": {
        "id": "AHcPxl8FNFDI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Key predictors of loan default include FICO score, income-to-installment ratio, and revolving balance utilization.\")"
      ],
      "metadata": {
        "id": "HVvfn7iuNL9a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ethical Considerations"
      ],
      "metadata": {
        "id": "8xhHto10Njsy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "conf_matrix = confusion_matrix(y_test, y_pred_rf)\n",
        "print(conf_matrix)"
      ],
      "metadata": {
        "id": "E8VrUgSLNbC6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scalability and Future Work"
      ],
      "metadata": {
        "id": "Lr1AhrFYN0T2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('classifier', RandomForestClassifier())\n",
        "])\n",
        "\n",
        "pipeline.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "_cXQSlQKNeBZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Limitations include potential overfitting and the need for more diverse data.\")"
      ],
      "metadata": {
        "id": "F0QVc5AdN-QH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}